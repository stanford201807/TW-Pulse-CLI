# è¨ºæ–·å ±å‘Šï¼šPulse æœªèª¿ç”¨åå‘ä»£ç†å•é¡Œ

## å•é¡Œæè¿°

ç”¨æˆ¶åæ˜ ï¼špulse ç¨‹å¼é‹è¡Œæ™‚ï¼Œåå‘ä»£ç†ç›£æ§é¡¯ç¤º**æ²’æœ‰æ”¶åˆ°ä»»ä½•è«‹æ±‚**ã€‚

## å·²å®Œæˆçš„æª¢æŸ¥

### âœ… é…ç½®å·²æ­£ç¢ºè¨­å®š

#### `.env` æª”æ¡ˆ
```bash
GEMINI_API_KEY=sk-6d4331550a484aa18a8f9192b8781ddd
PULSE_AI__DEFAULT_MODEL=gemini/gemini-3-pro-high
PULSE_AI__GEMINI_API_BASE=http://127.0.0.1:8045/v1
```

#### `config/pulse.yaml` æª”æ¡ˆ
```yaml
ai:
  default_model: "gemini/gemini-3-flash"
  gemini_api_base: "http://127.0.0.1:8045/v1"
```

### âœ… åå‘ä»£ç†é‹è¡Œæ­£å¸¸

ä½¿ç”¨ OpenAI SDK ç›´æ¥æ¸¬è©¦ï¼š
- âœ“ `gemini-3-flash` èª¿ç”¨æˆåŠŸ
- âœ“ `gemini-3-pro-high` èª¿ç”¨æˆåŠŸ
- âœ“ 68 å€‹æ¨¡å‹å¯ç”¨

### âœ… ä»£ç¢¼é‚è¼¯æ­£ç¢º

`pulse/ai/client.py` ç¬¬ 122-124 è¡Œï¼š
```python
# If using Gemini with custom API base
if self.model.startswith("gemini/") and settings.ai.gemini_api_base:
    api_params["api_base"] = settings.ai.gemini_api_base
```

## ğŸ” æ½›åœ¨å•é¡Œåˆ†æ

### å•é¡Œ 1ï¼špulse ç¨‹å¼æœªé‡å•Ÿ

**æœ€å¯èƒ½çš„åŸå› **ï¼špulse ç¨‹å¼åœ¨é…ç½®æ›´æ–°ä¹‹å‰å•Ÿå‹•ï¼Œä»åœ¨ä½¿ç”¨èˆŠé…ç½®ã€‚

**è­‰æ“š**ï¼š
- ç”¨æˆ¶æåˆ°ç¨‹å¼å·²é‹è¡Œ 30 åˆ†é˜
- é…ç½®æ›´æ–°åœ¨æœ€è¿‘æ‰å®Œæˆ

**è§£æ±ºæ–¹æ³•**ï¼š
1. åœæ­¢ pulse ç¨‹å¼ï¼ˆCtrl+Cï¼‰
2. é‡æ–°å•Ÿå‹•ï¼š`pulse`

### å•é¡Œ 2ï¼šLiteLLM å¯èƒ½ä¸æ”¯æ´å®Œæ•´çš„ OpenAI æ ¼å¼

LiteLLM åœ¨èª¿ç”¨ Gemini æ™‚å¯èƒ½ä½¿ç”¨åŸç”Ÿ Google API æ ¼å¼è€Œé OpenAI æ ¼å¼ã€‚

**æª¢æŸ¥æ–¹æ³•**ï¼š
åœ¨ `pulse/ai/client.py` ä¸­æ·»åŠ æ—¥èªŒï¼š

```python
# åœ¨ç¬¬ 122 è¡Œä¹‹å¾Œæ·»åŠ 
if self.model.startswith("gemini/") and settings.ai.gemini_api_base:
    api_params["api_base"] = settings.ai.gemini_api_base
    log.info(f"Using custom API base: {api_params['api_base']}")  # æ·»åŠ æ­¤è¡Œ
    log.info(f"API params: {api_params}")  # æ·»åŠ æ­¤è¡Œ
```

## ğŸ“ å»ºè­°çš„æ¸¬è©¦æ­¥é©Ÿ

### æ­¥é©Ÿ 1ï¼šç¢ºèª pulse å·²é‡å•Ÿ

```powershell
# åœæ­¢ç›®å‰çš„ pulseï¼ˆå¦‚æœæ­£åœ¨é‹è¡Œï¼‰
# æŒ‰ Ctrl+C

# é‡æ–°å•Ÿå‹•
pulse
```

### æ­¥é©Ÿ 2ï¼šå•Ÿç”¨è©³ç´°æ—¥èªŒ

ä¿®æ”¹ `.env` æª”æ¡ˆæ·»åŠ ï¼š
```bash
PULSE_DEBUG=true
```

### æ­¥é©Ÿ 3ï¼šç›£æ§æ—¥èªŒèˆ‡åå‘ä»£ç†

1. åœ¨ä¸€å€‹çµ‚ç«¯é‹è¡Œ pulse
2. åœ¨å¦ä¸€å€‹çµ‚ç«¯ç›£æ§åå‘ä»£ç†æ—¥èªŒ
3. åœ¨ pulse ä¸­è¼¸å…¥æ¸¬è©¦è¨Šæ¯
4. è§€å¯Ÿåå‘ä»£ç†æ˜¯å¦æ”¶åˆ°è«‹æ±‚

### æ­¥é©Ÿ 4ï¼šå¦‚æœä»ç„¡è«‹æ±‚

å¯èƒ½éœ€è¦ä¿®æ”¹ LiteLLM èª¿ç”¨æ–¹å¼ï¼Œæ”¹ç”¨ç›´æ¥ HTTP è«‹æ±‚æˆ– OpenAI SDKã€‚

## ğŸ”§ å‚™é¸æ–¹æ¡ˆ

å¦‚æœ LiteLLM ç„¡æ³•æ­£ç¢ºä½¿ç”¨åå‘ä»£ç†ï¼Œå¯ä»¥è€ƒæ…®ï¼š

### æ–¹æ¡ˆ Aï¼šä¿®æ”¹ç‚ºç›´æ¥ä½¿ç”¨ OpenAI SDK

ä¿®æ”¹ `pulse/ai/client.py`ï¼Œç•¶æª¢æ¸¬åˆ° Gemini + custom api_base æ™‚ï¼Œæ”¹ç”¨ OpenAI SDKï¼š

```python
if self.model.startswith("gemini/") and settings.ai.gemini_api_base:
    # ä½¿ç”¨ OpenAI SDK ç›´æ¥èª¿ç”¨
    from openai import AsyncOpenAI
    client = AsyncOpenAI(
        base_url=settings.ai.gemini_api_base,
        api_key=os.environ.get("GEMINI_API_KEY")
    )
    # ä½¿ç”¨ OpenAI æ ¼å¼èª¿ç”¨
    ...
```

### æ–¹æ¡ˆ Bï¼šè¨­å®š LiteLLM ç’°å¢ƒè®Šæ•¸

å˜—è©¦è¨­å®š LiteLLM ç‰¹å®šçš„ç’°å¢ƒè®Šæ•¸ï¼š

```bash
# åœ¨ .env ä¸­æ·»åŠ 
LITELLM_PROXY=http://127.0.0.1:8045/v1
```

## â­ï¸ ä¸‹ä¸€æ­¥è¡Œå‹•

**ç«‹å³åŸ·è¡Œ**ï¼š
1. âœ… åœæ­¢ pulse ç¨‹å¼
2. âœ… é‡æ–°å•Ÿå‹• pulse
3. âœ… åœ¨ pulse ä¸­è¼¸å…¥æ¸¬è©¦è¨Šæ¯
4. âœ… æª¢æŸ¥åå‘ä»£ç†æ—¥èªŒ

å¦‚æœä»æ²’æœ‰æ”¶åˆ°è«‹æ±‚ï¼Œéœ€è¦æ·»åŠ æ›´è©³ç´°çš„æ—¥èªŒä¾†è¨ºæ–· LiteLLM çš„å¯¦éš›è¡Œç‚ºã€‚

---

**è¨ºæ–·æ™‚é–“**: 2026-01-22 20:40  
**ç‹€æ…‹**: ç­‰å¾… pulse é‡å•Ÿæ¸¬è©¦
